# -*- coding: utf-8 -*-
"""ESE5460_Project_GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11ME3pkHkMhgHNqvbcMk79ZV3vXYp9kbI
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision.datasets import MNIST
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from torch.utils.tensorboard import SummaryWriter

def get_data(batch_size):

    """
    Helper function to download & transform MNIST data
    """

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,)),
    ])

    train_data = MNIST(root="dataset/", train=True, transform=transform, download=True)
    val_data = MNIST(root="dataset/", train=False, transform=transform, download=True)

    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)

    return train_data, train_loader, val_data, val_loader

class Discriminator(nn.Module):
    def __init__(self, in_features):
        super().__init__()

        self.hidden_1 = nn.Sequential(
          nn.Linear(in_features, 1024),
          nn.LeakyReLU(0.01),
          nn.Dropout(0.2)
        )

        self.hidden_2 = nn.Sequential(
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.01),
            nn.Dropout(0.2)
        )
        self.hidden_3 = nn.Sequential(
            nn.Linear(512, 256),
            nn.LeakyReLU(0.01),
            nn.Dropout(0.2)
        )
        self.out = nn.Sequential(
            nn.Linear(256, 1),
        )

    def forward(self, x):
        x = self.hidden_1(x)
        x = self.hidden_2(x)
        x = self.hidden_3(x)
        x = self.out(x)
        return x


class Generator(nn.Module):
    def __init__(self, z_features, out_dim):
        super().__init__()

        self.hidden_1 = nn.Sequential(
            nn.Linear(z_features, 256),
            nn.LeakyReLU(0.01)
        )
        self.hidden_2 = nn.Sequential(
            nn.Linear(256, 512),
            nn.LeakyReLU(0.01)
        )
        self.hidden_3 = nn.Sequential(
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.01)
        )

        self.out = nn.Sequential(
            nn.Linear(1024, out_dim),
            nn.Tanh()
        )


    def forward(self, x):
        x = self.hidden_1(x)
        x = self.hidden_2(x)
        x = self.hidden_3(x)
        x = self.out(x)
        return x

def train(discriminator, generator, disc_optimizer, gen_optimizer, criterion, train_loader, val_loader, epochs, device):

    """Train the GANs network"""

    # Tensorboard for logging
    writer_fake = SummaryWriter(f"logs/GAN_MNIST/fake")
    writer_real = SummaryWriter(f"logs/GAN_MNIST/real")
    log_step = 0


    for epoch in range(epochs):

        disc_losses = []
        gen_losses = []

        for batch_idx, (real_images, _) in enumerate(train_loader):
            real_images = real_images.view(-1, 784).to(device)
            batch_size = real_images.shape[0]


            #===============================
            # Discriminator Network Training
            #===============================

            # Loss of the discriminator on MNIST image inputs and real_labels
            discriminator.train()
            disc_real = discriminator(real_images)
            loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))

            # Loss of the discriminator on fake images generated by the generator
            noise = torch.randn(batch_size, noise_dim).to(device)

            generator.eval()
            with torch.no_grad():
              fake_images = generator(noise)

            disc_fake = discriminator(fake_images)
            loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))

            # Total discriminator loss
            disc_loss_total = loss_disc_real + loss_disc_fake

            # Backpropagating the discriminator loss
            disc_optimizer.zero_grad()
            disc_loss_total.backward()
            disc_optimizer.step()


            #===============================
            # Generator Network Training
            #===============================

            # Loss of the generator
            generator.train()
            noise = torch.randn(batch_size, noise_dim).to(device)
            fake_images = generator(noise)

            discriminator.eval()
            disc_fake = discriminator(fake_images)
            loss_gen = criterion(disc_fake, torch.ones_like(disc_fake))

            # Backpropagating the generator loss
            gen_optimizer.zero_grad()
            loss_gen.backward()
            gen_optimizer.step()

            # Log the losses
            disc_losses.append(disc_loss_total.item())
            gen_losses.append(loss_gen.item())

            if batch_idx == 0:

                print(
                    f"Epoch [{epoch}/{epochs}] \
                      Learning Rate: {lr}\
                      Discriminator Mean Loss: {torch.mean(torch.FloatTensor(disc_losses)):.4f}, \
                      Generator Mean Loss: {torch.mean(torch.FloatTensor(gen_losses)):.4f}"
                )

                with torch.no_grad():
                    fake_images = generator(val_noise).detach().cpu().reshape(-1, 1, 28, 28)
                    real_images = real_images.reshape(-1, 1, 28, 28)
                    img_grid_fake = torchvision.utils.make_grid(fake_images, normalize=True)
                    img_grid_real = torchvision.utils.make_grid(real_images, normalize=True)

                    writer_fake.add_image("Generated Fake MNIST Images", img_grid_fake, global_step=log_step)
                    writer_real.add_image("MNIST Real Images", img_grid_real, global_step=log_step)

                    log_step += 1

# Configurations --------------------------------> TO BE FINE TUNED FOR TRAINING

lr = 0.0002
batch_size = 64
epochs = 20

img_dim = 1 * 28 * 28  #784
noise_dim = 100

device = "cuda" if torch.cuda.is_available() else "cpu"
criterion = nn.BCEWithLogitsLoss()

#Initiate generator & discriminator & random noise for validation/logging

generator = Generator(noise_dim, img_dim).to(device)
discriminator = Discriminator(img_dim).to(device)

val_noise = torch.randn(batch_size, noise_dim).to(device)

# Optimizers for the discriminator & the generator

disc_optimizer = optim.Adam(discriminator.parameters(), lr=lr)
gen_optimizer = optim.Adam(generator.parameters(), lr=lr)

#download data

train_data, train_loader, val_data, val_loader = get_data(batch_size)

#Train the GAN network

train(discriminator, generator, disc_optimizer, gen_optimizer, criterion, train_loader, val_loader, epochs, device)

torch.save(discriminator.state_dict(), 'discriminator_state_dict.pth')
torch.save(generator.state_dict(), 'generator_state_dict.pth')

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
#Display images on tensorboard

# %load_ext tensorboard
# %tensorboard --logdir='./logs'