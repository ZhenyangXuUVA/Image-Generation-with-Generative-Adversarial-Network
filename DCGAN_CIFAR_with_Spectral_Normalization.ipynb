{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Pohxw7vYKwyP"},"outputs":[],"source":["import os\n","import shutil\n","import pickle\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","import torch.nn.utils.spectral_norm as spectral_norm\n","import numpy as np\n","from torchvision.models import inception_v3, Inception_V3_Weights\n","from scipy.linalg import sqrtm\n","from torchvision.datasets import CIFAR10\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from google.colab import drive\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14368,"status":"ok","timestamp":1701239069140,"user":{"displayName":"Jihong Song","userId":"04899183196512171169"},"user_tz":480},"id":"QydzP3hbv9HV","outputId":"06c9847a-1c83-41e2-81ef-9110b200cc5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uz5PAUSnJbv"},"outputs":[],"source":["def get_data(batch_size, image_channels, image_height_width):\n","\n","    \"\"\"\n","    Helper function to download & transform CIFAR data\n","    \"\"\"\n","\n","    transform = transforms.Compose([\n","        transforms.Resize(image_height_width),  # reshape the CIFAR images from 32x32 to 64x64\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.5 for _ in range(image_channels)], [0.5 for _ in range(image_channels)]),\n","    ])\n","\n","    train_data = CIFAR10(root='./dataset', train=True, transform=transform, download=True)\n","    val_data = CIFAR10(root='./dataset', train=False, transform=transform, download=True)\n","\n","    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n","\n","    return train_data, train_loader, val_data, val_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sly8dA3mw-EO"},"outputs":[],"source":["class DCGAN_Discriminator(nn.Module):\n","    def __init__(self, img_channels, features_disc):\n","        super().__init__()\n","\n","        self.disc = nn.Sequential(\n","\n","            # first Conv2d layer\n","            spectral_norm(nn.Conv2d(img_channels, features_disc, kernel_size=4, stride=2, padding=1)),       # output H x W = 32x32\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # middle _conv2d_layer(in_channels, out_channels, kernel_size, stride, padding)\n","            self._conv2d_layer(features_disc, features_disc * 2, 4, 2, 1),                          # output H x W = 16x16\n","            self._conv2d_layer(features_disc * 2, features_disc * 4, 4, 2, 1),                      # output H x W = 8x8\n","            self._conv2d_layer(features_disc * 4, features_disc * 8, 4, 2, 1),                      # output H x W = 4x4\n","\n","            # last conv2d layer to make 4x4 into 1x1\n","            spectral_norm(nn.Conv2d(features_disc * 8, 1, kernel_size=4, stride=2, padding=0)),                 # output H x W = 1x1\n","        )\n","\n","\n","    # helper function to abstract each Conv2d layer in the middle\n","    def _conv2d_layer(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            spectral_norm(nn.Conv2d(\n","                in_channels,\n","                out_channels,\n","                kernel_size,\n","                stride,\n","                padding,\n","                bias=False,\n","            )),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","\n","    def forward(self, x):\n","        # input: batch_size x img_channels x 64 x 64\n","        return self.disc(x)\n","\n","\n","\n","class DCGAN_Generator(nn.Module):\n","\n","    def __init__(self, noise_dim, img_channels, features_gen):\n","        super().__init__()\n","\n","        self.gen = nn.Sequential(\n","\n","            self._convTranspose2d_layer(noise_dim, features_gen * 16, 4, 1, 0),         # output H x W = 4x4\n","            self._convTranspose2d_layer(features_gen * 16, features_gen * 8, 4, 2, 1),  # output H x W = 8x8\n","            self._convTranspose2d_layer(features_gen * 8, features_gen * 4, 4, 2, 1),   # output H x W = 16x16\n","            self._convTranspose2d_layer(features_gen * 4, features_gen * 2, 4, 2, 1),   # output H x W = 32x32\n","\n","            # last ConvTranspose2d layer to output image size = 64 x 64\n","            nn.ConvTranspose2d(\n","                features_gen * 2, img_channels, kernel_size=4, stride=2, padding=1      # output H x W = 64x64\n","            ),\n","\n","            nn.Tanh(),\n","        )\n","\n","\n","    # helper function to abstract each ConvTranspose2d layer in the middle\n","    def _convTranspose2d_layer(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(\n","                in_channels,\n","                out_channels,\n","                kernel_size,\n","                stride,\n","                padding,\n","                bias=False,\n","            ),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","\n","    def forward(self, x):\n","        # Input: batch_size x noise_dim x 1 x 1\n","        return self.gen(x)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTM1cSjfm_gV"},"outputs":[],"source":["def initialize_weights(model):\n","    # Initialize weights with mean=0, stdev=0.02 according to the DCGAN paper\n","    for m in model.modules():\n","        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","            nn.init.normal_(m.weight.data, 0.0, 0.02)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VwQHtn_73Fe"},"outputs":[],"source":["\n","def train(discriminator, generator, disc_optimizer, gen_optimizer, criterion, train_loader, val_loader, epochs, device):\n","\n","    \"\"\"\n","    Helper function to train the DCGAN network with spectral normalization\n","    return: mean disc_loss and gen_loss for each epoch\n","    \"\"\"\n","\n","    # Tensorboard for logging\n","    writer_fake = SummaryWriter(f\"logs/SN_DCGAN_CIFAR/fake\")\n","    writer_real = SummaryWriter(f\"logs/SN_DCGAN_CIFAR/real\")\n","    log_step = 0\n","\n","\n","    for epoch in range(epochs):\n","\n","        disc_losses = []\n","        gen_losses = []\n","\n","        for batch_idx, (real_images, _) in enumerate(train_loader):\n","            real_images = real_images.to(device)\n","            batch_size = real_images.shape[0]\n","\n","\n","            #===============================\n","            # Discriminator Network Training\n","            #===============================\n","\n","            # Loss of the discriminator on CIFAR image inputs and real_labels\n","            discriminator.train()\n","            disc_real = discriminator(real_images)\n","            loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n","\n","            # Loss of the discriminator on fake images generated by the generator\n","            noise = torch.randn(batch_size, noise_dim, 1, 1).to(device)\n","\n","            generator.eval()\n","            with torch.no_grad():\n","              fake_images = generator(noise)\n","\n","            disc_fake = discriminator(fake_images)\n","            loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","\n","            # Total discriminator loss\n","            disc_loss_total = loss_disc_real + loss_disc_fake\n","\n","            # Backpropagating the discriminator loss\n","            disc_optimizer.zero_grad()\n","            disc_loss_total.backward()\n","            disc_optimizer.step()\n","\n","\n","            #===============================\n","            # Generator Network Training\n","            #===============================\n","\n","            # Loss of the generator\n","            generator.train()\n","            noise = torch.randn(batch_size, noise_dim, 1, 1).to(device)\n","            fake_images = generator(noise)\n","\n","            disc_fake = discriminator(fake_images)\n","            loss_gen = criterion(disc_fake, torch.ones_like(disc_fake))\n","\n","            # Backpropagating the generator loss\n","            gen_optimizer.zero_grad()\n","            loss_gen.backward()\n","            gen_optimizer.step()\n","\n","            # Log the losses\n","            disc_losses.append(disc_loss_total.item())\n","            gen_losses.append(loss_gen.item())\n","\n","\n","\n","        print(\n","            f\"Epoch [{epoch}/{epochs}] \\\n","              Learning Rate: {LEARNING_RATE}\\\n","              SN Discriminator Mean Loss: {torch.mean(torch.FloatTensor(disc_losses)):.4f}, \\\n","              SN Generator Mean Loss: {torch.mean(torch.FloatTensor(gen_losses)):.4f}\"\n","        )\n","\n","        with torch.no_grad():\n","            fake_images = generator(val_noise)\n","            img_grid_fake = torchvision.utils.make_grid(fake_images[:64], normalize=True)\n","            img_grid_real = torchvision.utils.make_grid(real_images[:64], normalize=True)\n","\n","            writer_fake.add_image(\"Fake CIFAR Images\", img_grid_fake, global_step=log_step)\n","            writer_real.add_image(\"Real CIFAR Images\", img_grid_real, global_step=log_step)\n","\n","            log_step += 1\n","\n","    return disc_losses, gen_losses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-lG9o1cn_iC"},"outputs":[],"source":["LEARNING_RATE = 0.0001\n","BATCH_SIZE = 128\n","EPOCHS = 25\n","IMAGE_HEIGHT_WIDTH = 64\n","IMAGE_CHANNELS = 3\n","FEATURES_DISC = 64\n","FEATURES_GEN = 64\n","noise_dim = 100\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mO6JvaouvA-I"},"outputs":[],"source":["discriminator = DCGAN_Discriminator(IMAGE_CHANNELS, FEATURES_DISC).to(device)\n","generator = DCGAN_Generator(noise_dim, IMAGE_CHANNELS, FEATURES_GEN).to(device)\n","\n","initialize_weights(generator)\n","initialize_weights(discriminator)\n","\n","val_noise = torch.randn(64, noise_dim, 1, 1).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BxR25QZ4xUBQ"},"outputs":[],"source":["\n","gen_optimizer = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n","disc_optimizer = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n","criterion = nn.BCEWithLogitsLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9256,"status":"ok","timestamp":1701239210961,"user":{"displayName":"Jihong Song","userId":"04899183196512171169"},"user_tz":480},"id":"y1HL-FdkyWiF","outputId":"fa0b94ab-ace4-4aa4-dfce-c5112e1698e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:04<00:00, 41847029.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n","Files already downloaded and verified\n"]}],"source":["train_data, train_loader, val_data, val_loader = get_data(BATCH_SIZE, IMAGE_CHANNELS, IMAGE_HEIGHT_WIDTH)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-s6b99Krymqj","outputId":"8c7d8c74-cf33-4088-a318-048c7f79b0ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.2523,               SN Generator Mean Loss: 2.2272\n","Epoch [1/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.1709,               SN Generator Mean Loss: 3.3459\n","Epoch [2/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.6938,               SN Generator Mean Loss: 1.2959\n","Epoch [3/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.8585,               SN Generator Mean Loss: 0.9696\n","Epoch [4/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.7797,               SN Generator Mean Loss: 0.7341\n","Epoch [5/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.6735,               SN Generator Mean Loss: 0.5839\n","Epoch [6/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.5598,               SN Generator Mean Loss: 0.4669\n","Epoch [7/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.6710,               SN Generator Mean Loss: 0.4941\n","Epoch [8/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.5068,               SN Generator Mean Loss: 0.4089\n","Epoch [9/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.7117,               SN Generator Mean Loss: 0.5912\n","Epoch [10/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.8928,               SN Generator Mean Loss: 0.6468\n","Epoch [11/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.9327,               SN Generator Mean Loss: 0.7190\n","Epoch [12/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.8269,               SN Generator Mean Loss: 0.7712\n","Epoch [13/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.7060,               SN Generator Mean Loss: 0.5392\n","Epoch [14/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.8302,               SN Generator Mean Loss: 0.5986\n","Epoch [15/25]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.9767,               SN Generator Mean Loss: 0.6894\n"]}],"source":["disc_losses, gen_losses = train(discriminator, generator, disc_optimizer, gen_optimizer, criterion, train_loader, val_loader, EPOCHS, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wzm9NV4qXtkT"},"outputs":[],"source":["torch.save(discriminator.state_dict(), 'sn_dcgan_discriminator_state_dict.pth')\n","torch.save(generator.state_dict(), 'sn_dcgan_generator_state_dict.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bEn-bFDzULs"},"outputs":[],"source":["#Display images on tensorboard\n","\n","# %load_ext tensorboard\n","# %tensorboard --logdir='./logs'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LypZwwxpSOgy"},"outputs":[],"source":["del train_data, train_loader, disc_losses, gen_losses, discriminator, val_noise\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cX10Km68_0H8"},"outputs":[],"source":["##################################\n","# Helper Functions for Evaluation\n","##################################\n","\n","\n","# Initialize the pretrained Inception v3 for computing FID score\n","inception_model = inception_v3(weights=Inception_V3_Weights.DEFAULT).to(device)\n","inception_model.fc = torch.nn.Identity()\n","inception_model.eval()\n","\n","def extract_features(tensors, model):\n","    # Ensure model is in evaluation mode\n","    model.eval()\n","\n","    # Preprocess and normalize the tensors if they're not already\n","    preprocess = transforms.Compose([\n","        transforms.Resize((299, 299), antialias=True),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    # Initialize an empty list to hold features\n","    features_list = []\n","\n","    # No gradients needed\n","    with torch.no_grad():\n","        for tensor in tensors:\n","            # Reshape and normalize the tensor\n","            if tensor.ndim == 3:  # If single image tensor, add batch dimension\n","                tensor = tensor.unsqueeze(0)\n","            tensor = preprocess(tensor)\n","\n","            # Extract features\n","            feature = model(tensor)\n","            features_list.append(feature.cpu().numpy())\n","\n","    # Concatenate all features into a single numpy array\n","    features = np.concatenate(features_list, axis=0)\n","    return features\n","\n","\n","def calculate_fid(real_features, fake_features):\n","    # Check for NaNs or Infs in the real features\n","    if np.any(np.isnan(real_features)) or np.any(np.isinf(real_features)):\n","        real_features = np.nan_to_num(real_features)\n","\n","    # Check for NaNs or Infs in the fake features\n","    if np.any(np.isnan(fake_features)) or np.any(np.isinf(fake_features)):\n","        fake_features = np.nan_to_num(fake_features)\n","\n","    mu_real, sigma_real = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n","    mu_fake, sigma_fake = np.mean(fake_features, axis=0), np.cov(fake_features, rowvar=False)\n","\n","    eps = 1e-6\n","    covmean, _ = sqrtm((sigma_real + eps * np.eye(sigma_real.shape[0])) @ (sigma_fake + eps * np.eye(sigma_fake.shape[0])), disp=False)\n","    ssdiff = np.sum((mu_real - mu_fake) ** 2.0)\n","\n","    if np.iscomplexobj(covmean):\n","        covmean = covmean.real\n","    fid_score = ssdiff + np.trace(sigma_real + sigma_fake - 2.0 * covmean)\n","\n","    return fid_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhZSwQsrAEgd"},"outputs":[],"source":["##############################################################\n","# Helper function to compute FID score on validation dataset\n","##############################################################\n","\n","def get_FID_score(val_data, val_loader):\n","    generator.eval()\n","    num_images = len(val_data)  # Number of images in the validation set\n","    noise = torch.randn(num_images, noise_dim, 1, 1).to(device)\n","\n","\n","    #extract features for real images\n","    real_features_list = []\n","    for real_images, _ in val_loader:\n","        real_images = real_images.to(device)\n","        current_features = extract_features(real_images, inception_model)\n","        real_features_list.append(current_features)\n","        # save memory\n","        del real_images, current_features\n","        torch.cuda.empty_cache()\n","\n","    ## Concatenate all feature batches\n","    real_features = np.concatenate(real_features_list, axis=0)\n","\n","    # extract features for fake images\n","    fake_features_list = []\n","\n","    with torch.no_grad():\n","        for _ in range(0, num_images, BATCH_SIZE):\n","            noise_batch = torch.randn(BATCH_SIZE, noise_dim, 1, 1).to(device)\n","            fake_images_batch = generator(noise_batch)\n","            current_features = extract_features(fake_images_batch, inception_model)\n","            fake_features_list.append(current_features)\n","            # save memory\n","            del noise_batch, fake_images_batch, current_features\n","            torch.cuda.empty_cache()\n","\n","    # Concatenate all feature batches\n","    fake_features = np.concatenate(fake_features_list, axis=0)\n","\n","    nan_count_real = np.isnan(real_features).sum()\n","    inf_count_real = np.isinf(real_features).sum()\n","\n","    nan_count_fake = np.isnan(fake_features).sum()\n","    inf_count_fake = np.isinf(fake_features).sum()\n","\n","    print(\"Real features - NaNs:\", nan_count_real, \"Infs:\", inf_count_real)\n","    print(\"Fake features - NaNs:\", nan_count_fake, \"Infs:\", inf_count_fake)\n","\n","    # compute FID score\n","    SN_DCGAN_FID_score = calculate_fid(real_features, fake_features)\n","\n","    # save memory\n","    del real_features, real_features_list, fake_features, fake_features_list\n","    torch.cuda.empty_cache()\n","\n","    return SN_DCGAN_FID_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKcHUmpxT_F3"},"outputs":[],"source":["# get FID score\n","SN_DCGAN_FID_score = get_FID_score(val_data, val_loader)\n","print('SN_DCGAN_FID_score = ', SN_DCGAN_FID_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OM5_thue5np"},"outputs":[],"source":["##############################################################\n","# Helper function to evaluate discriminator accuracy\n","##############################################################\n","\n","def evaluate_discriminator(discriminator, val_data, val_loader):\n","    discriminator.eval()\n","\n","    # Get real images\n","    real_images = []\n","    for images, _ in val_loader:\n","        images = images.to(device)\n","        real_images.append(images)\n","    real_images = torch.cat(real_images, 0)\n","\n","\n","    # Get fake images\n","    fake_images = []\n","    num_fake_images = len(real_images)\n","\n","    for _ in range(0, num_fake_images, BATCH_SIZE):\n","        noise = torch.randn(BATCH_SIZE, noise_dim, 1, 1).to(device)\n","        batch_fake_images = generator(noise).to(device)\n","        fake_images.append(batch_fake_images)\n","    fake_images = torch.cat(fake_images, 0)\n","\n","\n","    # Concatenate real and fake images\n","    all_images = torch.cat((real_images, fake_images), 0)\n","\n","    # Labels: 1 for real images, 0 for fake images\n","    real_labels = torch.ones(real_images.size(0)).to(device)\n","    fake_labels = torch.zeros(fake_images.size(0)).to(device)\n","    all_labels = torch.cat((real_labels, fake_labels), 0)\n","\n","    # Predictions\n","    with torch.no_grad():\n","        predictions = discriminator(all_images).view(-1)\n","\n","    # Convert predictions to binary (0 or 1)\n","    predictions_binary = torch.round(torch.sigmoid(predictions))\n","\n","    # Calculate accuracy\n","    accuracy = accuracy_score(all_labels.cpu(), predictions_binary.cpu())\n","\n","    return accuracy\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TOR3iFlHLBpo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1701239114180,"user":{"displayName":"Jihong Song","userId":"04899183196512171169"},"user_tz":480},"id":"rUOYdp7be5px","outputId":"7a3fdabc-8a17-4b7a-d8a2-b2ada8b4226c"},"outputs":[{"name":"stdout","output_type":"stream","text":["ls: cannot access '/content/gdrive/MyDrive/dcgan_sn': No such file or directory\n"]}],"source":["!ls /content/gdrive/MyDrive/dcgan_sn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"DQuqNC4FQBDb","outputId":"52b851a3-ed46-4d7e-be04-0ef532a69e12"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch [0/80]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.3053,               SN Generator Mean Loss: 2.1731\n","Epoch [1/80]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.2824,               SN Generator Mean Loss: 2.2058\n","Epoch [2/80]               Learning Rate: 0.0001              SN Discriminator Mean Loss: 0.6681,               SN Generator Mean Loss: 1.0087\n"]}],"source":["#Train the DCGAN_CIFAR_with_Spectral_Normalization, with 100 epochs\n","\n","epochs = 80\n","for lr in [0.0001, 0.00001, 0.000001]:\n","    LEARNING_RATE = lr\n","    generator =  DCGAN_Generator(noise_dim, IMAGE_CHANNELS, FEATURES_GEN).to(device)\n","    discriminator = DCGAN_Discriminator(IMAGE_CHANNELS, FEATURES_DISC).to(device)\n","\n","    initialize_weights(generator)\n","    initialize_weights(discriminator)\n","\n","    val_noise = torch.randn(64, noise_dim, 1, 1).to(device)\n","\n","    gen_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n","    disc_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n","    criterion = nn.BCEWithLogitsLoss()\n","\n","    train_data, train_loader, val_data, val_loader = get_data(BATCH_SIZE, IMAGE_CHANNELS, IMAGE_HEIGHT_WIDTH)\n","\n","    disc_losses, gen_losses = train(discriminator, generator, disc_optimizer, gen_optimizer, criterion, train_loader, val_loader, epochs, device)\n","\n","\n","    # get the FID score\n","    SN_DCGAN_FID_score = get_FID_score(val_data, val_loader)\n","    print(f'learning rate = {lr}, \\\n","          SN_DCGAN_FID_score = {SN_DCGAN_FID_score}')\n","\n","    dirname = f'/content/gdrive/MyDrive/dcgan_sn/{lr:.0E}'\n","\n","    if os.path.exists(dirname):\n","        shutil.rmtree(dirname)\n","\n","    shutil.copytree(\"./logs/SN_DCGAN_CIFAR\", f'{dirname}/tensorboard')\n","\n","    with open(f\"{dirname}/SN_FID.pkl\", \"wb\") as f:\n","        pickle.dump(SN_DCGAN_FID_score, f)\n","\n","    with open(f\"{dirname}/sn_results.pkl\", \"wb\") as f:\n","        pickle.dump(disc_losses, f)\n","        pickle.dump(gen_losses, f)\n","\n","    torch.save(generator.state_dict(), f\"{dirname}/sn_generator.pth\")\n","    torch.save(discriminator.state_dict(), f\"{dirname}/sn_discriminator.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DknfGxYqOGbK"},"outputs":[],"source":["#Train the DCGAN_CIFAR_with_Spectral_Normalization, with 100 epochs\n","\n","epochs = 100\n","for lr in [0.00001, 0.000001]:\n","    LEARNING_RATE = lr\n","    generator =  DCGAN_Generator(noise_dim, IMAGE_CHANNELS, FEATURES_GEN).to(device)\n","    discriminator = DCGAN_Discriminator(IMAGE_CHANNELS, FEATURES_DISC).to(device)\n","\n","    initialize_weights(generator)\n","    initialize_weights(discriminator)\n","\n","    val_noise = torch.randn(64, noise_dim, 1, 1).to(device)\n","\n","    gen_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n","    disc_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n","    criterion = nn.BCEWithLogitsLoss()\n","\n","    train_data, train_loader, val_data, val_loader = get_data(BATCH_SIZE, IMAGE_CHANNELS, IMAGE_HEIGHT_WIDTH)\n","\n","    disc_losses, gen_losses = train(discriminator, generator, disc_optimizer, gen_optimizer, criterion, train_loader, val_loader, epochs, device)\n","\n","\n","    # get the FID score\n","    SN_DCGAN_FID_score = get_FID_score(val_data, val_loader)\n","    print(f'learning rate = {lr}, \\\n","          SN_DCGAN_FID_score = {SN_DCGAN_FID_score}')\n","\n","    dirname = f'/content/gdrive/MyDrive/dcgan_sn/{lr:.0E}'\n","\n","    if os.path.exists(dirname):\n","        shutil.rmtree(dirname)\n","\n","    shutil.copytree(\"./logs/SN_DCGAN_CIFAR\", f'{dirname}/tensorboard')\n","\n","    with open(f\"{dirname}/SN_FID.pkl\", \"wb\") as f:\n","        pickle.dump(SN_DCGAN_FID_score, f)\n","\n","    with open(f\"{dirname}/sn_results.pkl\", \"wb\") as f:\n","        pickle.dump(disc_losses, f)\n","        pickle.dump(gen_losses, f)\n","\n","    torch.save(generator.state_dict(), f\"{dirname}/sn_generator.pth\")\n","    torch.save(discriminator.state_dict(), f\"{dirname}/sn_discriminator.pth\")"]},{"cell_type":"code","source":["# load the saved discriminator\n","discriminator = DCGAN_Discriminator(IMAGE_CHANNELS, FEATURES_DISC).to(device)\n","initialize_weights(discriminator)\n","checkpoint = torch.load(\"{dirname}/sn_discriminator.pth\")\n","discriminator.load_state_dict(checkpoint[discriminator.state_dict()])"],"metadata":{"id":"IBXzkvNCKZCI","colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"status":"error","timestamp":1701375230362,"user_tz":480,"elapsed":696,"user":{"displayName":"Jihong Song","userId":"04899183196512171169"}},"outputId":"48de4682-1255-4703-8edf-3e1749cfaa95"},"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load the saved discriminator\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m \u001b[43mDCGAN_Discriminator\u001b[49m(IMAGE_CHANNELS, FEATURES_DISC)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m initialize_weights(discriminator)\n\u001b[1;32m      4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{dirname}\u001b[39;00m\u001b[38;5;124m/sn_discriminator.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'DCGAN_Discriminator' is not defined"]}]},{"cell_type":"code","source":["    # get the discriminator accuracy\n","    accuracy = evaluate_discriminator(discriminator, val_data, val_loader)\n","    print(f\"Accuracy: {accuracy}\")"],"metadata":{"id":"Csi9vY22KV_H"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}